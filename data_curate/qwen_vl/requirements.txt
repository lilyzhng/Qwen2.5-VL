# Core dependencies for Qwen3-VL local inference
transformers>=4.57.0
torch>=2.0.0
torchvision>=0.15.0
pillow>=9.0.0

# Optional: For faster inference (requires compatible GPU)
# flash-attn>=2.0.0

